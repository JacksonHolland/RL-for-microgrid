{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea3b27a-b06a-4677-b814-dd840452df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "832f8312-ca66-49ee-9f24-84f2cce2fa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the file:\n",
      "- actions\n",
      "  Shape: (2022, 1000, 2)\n",
      "  Data type: float32\n",
      "  Min value: -1.0\n",
      "  Max value: 1.0\n",
      "  Mean value: 0.41104790568351746\n",
      "  Has NaNs: False\n",
      "  Has Infs: False\n",
      "\n",
      "- costs\n",
      "  Shape: (2022, 1000)\n",
      "  Data type: float32\n",
      "  Min value: 0.0\n",
      "  Max value: 1.0\n",
      "  Mean value: 0.03068496473133564\n",
      "  Has NaNs: False\n",
      "  Has Infs: False\n",
      "\n",
      "- observations\n",
      "  Shape: (2022, 1000, 60)\n",
      "  Data type: float32\n",
      "  Min value: -19.96635627746582\n",
      "  Max value: 19.938732147216797\n",
      "  Mean value: 0.30550599098205566\n",
      "  Has NaNs: False\n",
      "  Has Infs: False\n",
      "\n",
      "- rewards\n",
      "  Shape: (2022, 1000)\n",
      "  Data type: float32\n",
      "  Min value: -0.028873039409518242\n",
      "  Max value: 1.0294471979141235\n",
      "  Mean value: 0.012595054693520069\n",
      "  Has NaNs: False\n",
      "  Has Infs: False\n",
      "\n",
      "- terminals\n",
      "  Shape: (2022, 1000)\n",
      "  Data type: bool\n",
      "  Min value: False\n",
      "  Max value: False\n",
      "  Mean value: 0.0\n",
      "  Has NaNs: False\n",
      "  Has Infs: False\n",
      "\n",
      "- timeouts\n",
      "  Shape: (2022, 1000)\n",
      "  Data type: bool\n",
      "  Min value: False\n",
      "  Max value: True\n",
      "  Mean value: 0.001\n",
      "  Has NaNs: False\n",
      "  Has Infs: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def inspect_h5(file_path):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        print(\"Keys in the file:\")\n",
    "        for key in f.keys():\n",
    "            print(f\"- {key}\")\n",
    "            data = f[key][()]\n",
    "            print(f\"  Shape: {data.shape}\")\n",
    "            print(f\"  Data type: {data.dtype}\")\n",
    "            print(f\"  Min value: {np.min(data)}\")\n",
    "            print(f\"  Max value: {np.max(data)}\")\n",
    "            print(f\"  Mean value: {np.mean(data)}\")\n",
    "            print(f\"  Has NaNs: {np.isnan(data).any()}\")\n",
    "            print(f\"  Has Infs: {np.isinf(data).any()}\")\n",
    "            print()\n",
    "\n",
    "# Use the function\n",
    "inspect_h5('raw_trajectories.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1b63d11-7526-4b58-b7b4-bea0157fe7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU Name: NVIDIA RTX A3000 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# Print the name of the GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b78efb72-0745-449a-ba0d-7f4e16255f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions\n",
      "costs\n",
      "observations\n",
      "rewards\n",
      "terminals\n",
      "timeouts\n"
     ]
    }
   ],
   "source": [
    "def print_h5_structure(file_path):\n",
    "    with h5py.File(file_path, 'r') as hf:\n",
    "        def print_attrs(name, obj):\n",
    "            print(name)\n",
    "            for key, val in obj.attrs.items():\n",
    "                print(f\"    {key}: {val}\")\n",
    "        \n",
    "        hf.visititems(print_attrs)\n",
    "\n",
    "print_h5_structure('raw_trajectories.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2cb280f-56fd-4a6d-8070-0c917c6f9838",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleUnet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.down1 = nn.Linear(in_channels, 256)\n",
    "        self.down2 = nn.Linear(256, 512)\n",
    "        self.down3 = nn.Linear(512, 1024)\n",
    "        self.up1 = nn.Linear(1024, 512)\n",
    "        self.up2 = nn.Linear(512, 256)\n",
    "        self.up3 = nn.Linear(256, out_channels)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        b, seq_len, c = x.shape\n",
    "        t = t.unsqueeze(1).expand(-1, seq_len)\n",
    "        \n",
    "        x1 = F.relu(self.down1(x))\n",
    "        x2 = F.relu(self.down2(x1))\n",
    "        x3 = F.relu(self.down3(x2))\n",
    "        x = F.relu(self.up1(x3)) + x2\n",
    "        x = F.relu(self.up2(x)) + x1\n",
    "        return self.up3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08eb79e4-f413-4d48-87e4-a3e183c40eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "    def __init__(self, eps_model, betas, n_T):\n",
    "        super().__init__()\n",
    "        self.eps_model = eps_model\n",
    "        self.betas = betas\n",
    "        self.n_T = n_T\n",
    "        \n",
    "        # Pre-compute different terms for closed form\n",
    "        self.alphas = 1. - betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
    "        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "        self.sqrt_recip_alphas = torch.sqrt(1.0 / self.alphas)\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - self.alphas_cumprod)\n",
    "        self.posterior_variance = betas * (1. - self.alphas_cumprod_prev) / (1. - self.alphas_cumprod)\n",
    "        \n",
    "    def forward(self, x_0):\n",
    "        b, seq_len, c = x_0.shape\n",
    "        t = torch.randint(0, self.n_T, (b,)).to(x_0.device)\n",
    "        noise = torch.randn_like(x_0)\n",
    "        x_t = (\n",
    "            self.sqrt_alphas_cumprod[t][:, None, None] * x_0 + \n",
    "            self.sqrt_one_minus_alphas_cumprod[t][:, None, None] * noise\n",
    "        )\n",
    "        return self.eps_model(x_t, t), noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x, t, t_index):\n",
    "        betas_t = self.betas[t][:, None, None]\n",
    "        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t][:, None, None]\n",
    "        sqrt_recip_alphas_t = self.sqrt_recip_alphas[t][:, None, None]\n",
    "        \n",
    "        model_mean = sqrt_recip_alphas_t * (\n",
    "            x - betas_t * self.eps_model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
    "        )\n",
    "        \n",
    "        if t_index == 0:\n",
    "            return model_mean\n",
    "        else:\n",
    "            posterior_variance_t = self.posterior_variance[t][:, None, None]\n",
    "            noise = torch.randn_like(x)\n",
    "            return model_mean + torch.sqrt(posterior_variance_t) * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, seq_len, batch_size=16, channels=126):\n",
    "        device = next(self.parameters()).device\n",
    "        shape = (batch_size, seq_len, channels)\n",
    "        img = torch.randn(shape, device=device)\n",
    "        \n",
    "        for i in tqdm(reversed(range(0, self.n_T)), desc='sampling loop time step', total=self.n_T):\n",
    "            t = torch.full((batch_size,), i, device=device, dtype=torch.long)\n",
    "            img = self.p_sample(img, t, i)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f5afc04-5216-4645-b313-4c8509042b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with h5py.File(file_path, 'r') as hf:\n",
    "        observations = hf['observations'][:]\n",
    "        actions = hf['actions'][:]\n",
    "        rewards = hf['rewards'][:]\n",
    "        costs = hf['costs'][:]\n",
    "        terminals = hf['terminals'][:]\n",
    "        timeouts = hf['timeouts'][:]\n",
    "    \n",
    "    # Create next_observations by shifting observations\n",
    "    next_observations = np.roll(observations, -1, axis=1)\n",
    "    next_observations[:, -1] = observations[:, -1]  # Last step\n",
    "    \n",
    "    # Reshape 1D arrays to have a second dimension of 1\n",
    "    rewards = rewards[..., np.newaxis]\n",
    "    costs = costs[..., np.newaxis]\n",
    "    terminals = terminals[..., np.newaxis]\n",
    "    timeouts = timeouts[..., np.newaxis]\n",
    "    \n",
    "    # Combine all data into a single array\n",
    "    trajectories = np.concatenate([\n",
    "        observations,\n",
    "        next_observations,\n",
    "        actions,\n",
    "        rewards,\n",
    "        costs,\n",
    "        terminals,\n",
    "        timeouts\n",
    "    ], axis=2)\n",
    "    \n",
    "    return torch.FloatTensor(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37d70d2b-76e6-4821-bf89-1ab89c155fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def p_sample(model, x, t, t_index):\n",
    "    betas_t = model.betas[t]\n",
    "    sqrt_one_minus_alphas_cumprod_t = model.sqrt_one_minus_alphas_cumprod[t]\n",
    "    sqrt_recip_alphas_t = model.sqrt_recip_alphas[t]\n",
    "    \n",
    "    model_mean = sqrt_recip_alphas_t * (x - betas_t * model.eps_model(x, t) / sqrt_one_minus_alphas_cumprod_t)\n",
    "    \n",
    "    if t_index == 0:\n",
    "        return model_mean\n",
    "    else:\n",
    "        posterior_variance_t = model.posterior_variance[t]\n",
    "        noise = torch.randn_like(x)\n",
    "        return model_mean + torch.sqrt(posterior_variance_t) * noise\n",
    "\n",
    "@torch.no_grad()\n",
    "def p_sample_loop(model, shape):\n",
    "    device = next(model.parameters()).device\n",
    "    b = shape[0]\n",
    "    img = torch.randn(shape, device=device)\n",
    "    \n",
    "    for i in tqdm(reversed(range(0, model.n_T)), desc='sampling loop time step', total=model.n_T):\n",
    "        img = p_sample(model, img, torch.full((b,), i, device=device, dtype=torch.long), i)\n",
    "    return img\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(model, image_size, batch_size=16, channels=3):\n",
    "    return p_sample_loop(model, shape=(batch_size, channels, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc9a87f4-65a0-4e96-8220-1e44c83fdac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            return self.data[idx]\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading item at index {idx}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2af0410a-8227-4e82-9a55-dc1baff2bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMTrainer:\n",
    "    def __init__(self, ddpm, dataset, device, learning_rate=1e-4, batch_size=32):\n",
    "        self.ddpm = ddpm\n",
    "        self.device = device\n",
    "        self.dataset = dataset\n",
    "        self.dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        self.optimizer = torch.optim.Adam(ddpm.parameters(), lr=learning_rate)\n",
    "\n",
    "    def save_model(self, epoch, loss, filename):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.ddpm.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }\n",
    "        torch.save(checkpoint, filename)\n",
    "        print(f\"Model saved to {filename}\")\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        if os.path.isfile(filename):\n",
    "            checkpoint = torch.load(filename)\n",
    "            self.ddpm.load_state_dict(checkpoint['model_state_dict'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            epoch = checkpoint['epoch']\n",
    "            loss = checkpoint['loss']\n",
    "            print(f\"Model loaded from {filename}\")\n",
    "            return epoch, loss\n",
    "        else:\n",
    "            print(f\"No saved model found at {filename}\")\n",
    "            return 0, float('inf')\n",
    "\n",
    "    def train(self, num_epochs, model_filename):\n",
    "        start_epoch, best_loss = self.load_model(model_filename)\n",
    "        \n",
    "        for epoch in range(start_epoch, num_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for batch in tqdm(self.dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "                self.optimizer.zero_grad()\n",
    "                batch = batch.to(self.device)\n",
    "                predicted_noise, target_noise = self.ddpm(batch)\n",
    "                loss = F.mse_loss(predicted_noise, target_noise)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            \n",
    "            avg_loss = epoch_loss / len(self.dataloader)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "            \n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                self.save_model(epoch+1, best_loss, model_filename)\n",
    "        \n",
    "        print(\"Training completed.\")\n",
    "\n",
    "    def generate_trajectories(self, seq_len, batch_size, channels):\n",
    "        print(\"Generating new trajectories...\")\n",
    "        generated_trajectories = self.ddpm.sample(seq_len=seq_len, batch_size=batch_size, channels=channels)\n",
    "        print(\"Generated trajectories shape:\", generated_trajectories.shape)\n",
    "        return generated_trajectories\n",
    "\n",
    "    def generate_and_save_trajectories(self, seq_len, total_trajectories, channels, save_path, batch_size=10):\n",
    "        print(f\"Generating and saving {total_trajectories} trajectories in batches of {batch_size}...\")\n",
    "        \n",
    "        # Open a memory-mapped file for writing\n",
    "        shape = (total_trajectories, seq_len, channels)\n",
    "        memmap = np.memmap(save_path, dtype='float32', mode='w+', shape=shape)\n",
    "        \n",
    "        for start_idx in tqdm(range(0, total_trajectories, batch_size), desc=\"Generating batches\"):\n",
    "            end_idx = min(start_idx + batch_size, total_trajectories)\n",
    "            current_batch_size = end_idx - start_idx\n",
    "            \n",
    "            # Generate a batch of trajectories\n",
    "            with torch.no_grad():\n",
    "                generated_batch = self.ddpm.sample(seq_len=seq_len, batch_size=current_batch_size, channels=channels)\n",
    "            \n",
    "            # Move to CPU and convert to numpy\n",
    "            generated_batch_np = generated_batch.cpu().numpy()\n",
    "            \n",
    "            # Save to memmap\n",
    "            memmap[start_idx:end_idx] = generated_batch_np\n",
    "            \n",
    "            # Explicitly delete to free up memory\n",
    "            del generated_batch, generated_batch_np\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Flush the memmap to ensure all data is written\n",
    "        memmap.flush()\n",
    "        \n",
    "        print(f\"Generated trajectories saved to {save_path}\")\n",
    "        print(f\"Shape of saved trajectories: {shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e759d3-270d-48f9-ae71-0d81e2d8ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your main script would then look like this:\n",
    "if name == \"main\":\n",
    "    # Hyperparameters\n",
    "    n_T = 1000\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    betas = torch.linspace(1e-4, 0.02, n_T).to(device)\n",
    "\n",
    "    # Load data\n",
    "    file_path = 'raw_trajectories.h5'\n",
    "    trajectories = load_data(file_path)\n",
    "\n",
    "    in_channels = trajectories.shape[2]\n",
    "\n",
    "    print(f\"Trajectory shape: {trajectories.shape}\")\n",
    "    print(f\"Number of features per trajectory: {in_channels}\")\n",
    "\n",
    "    # Initialize models\n",
    "    eps_model = SimpleUnet(in_channels, in_channels).to(device)\n",
    "    ddpm = DDPM(eps_model, betas, n_T).to(device)\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = TrajectoryDataset(trajectories)\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = DDPMTrainer(ddpm, dataset, device)\n",
    "\n",
    "    # Train DDPM\n",
    "    model_filename = 'ddpm_model.pth'\n",
    "    num_epochs = 100\n",
    "    trainer.train(num_epochs, model_filename)\n",
    "\n",
    "     # Generate and save new trajectories\n",
    "    save_path = 'generated_trajectories.npy'\n",
    "    trainer.generate_and_save_trajectories(\n",
    "        seq_len=trajectories.shape[1], \n",
    "        total_trajectories=1000,  # This is the number of trajectories you want to generate\n",
    "        channels=trajectories.shape[2],\n",
    "        save_path=save_path,\n",
    "        batch_size=10  # Adjust this based on your GPU memory\n",
    "    )\n",
    "\n",
    "    print(\"Process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4105961e-fbae-4498-900a-540545d4dffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape of generated trajectories: (126000000,)\n",
      "Total number of elements: 126000000\n",
      "Inferred shape: (1000, 1000, 126)\n",
      "Data type: float32\n",
      "Min value: -760.2193603515625\n",
      "Max value: 938.1056518554688\n",
      "Mean value: 1.6578973531723022\n",
      "Has NaNs: False\n",
      "Has Infs: False\n",
      "\n",
      "Feature 0:\n",
      "  Min: -461.65472412109375\n",
      "  Max: 560.3864135742188\n",
      "  Mean: 14.21492862701416\n",
      "\n",
      "Feature 1:\n",
      "  Min: -661.8180541992188\n",
      "  Max: 938.1056518554688\n",
      "  Mean: 12.59593391418457\n",
      "\n",
      "Feature 2:\n",
      "  Min: -742.8836059570312\n",
      "  Max: 706.7652587890625\n",
      "  Mean: 33.1786994934082\n",
      "\n",
      "Feature 3:\n",
      "  Min: -283.9253845214844\n",
      "  Max: 299.37139892578125\n",
      "  Mean: 7.248508453369141\n",
      "\n",
      "Feature 4:\n",
      "  Min: -300.78656005859375\n",
      "  Max: 318.9814147949219\n",
      "  Mean: 1.6598554849624634\n",
      "\n",
      "Feature 5:\n",
      "  Min: -268.4080810546875\n",
      "  Max: 239.41165161132812\n",
      "  Mean: -0.9450872540473938\n",
      "\n",
      "Feature 6:\n",
      "  Min: -266.3388366699219\n",
      "  Max: 283.5146789550781\n",
      "  Mean: 0.24941018223762512\n",
      "\n",
      "Feature 7:\n",
      "  Min: -254.8743438720703\n",
      "  Max: 277.1191711425781\n",
      "  Mean: -0.33862096071243286\n",
      "\n",
      "Feature 8:\n",
      "  Min: -572.02392578125\n",
      "  Max: 203.36337280273438\n",
      "  Mean: -21.4462890625\n",
      "\n",
      "Feature 9:\n",
      "  Min: -323.6048278808594\n",
      "  Max: 350.128662109375\n",
      "  Mean: 0.969159722328186\n",
      "\n",
      "Feature 10:\n",
      "  Min: -337.8118896484375\n",
      "  Max: 323.71435546875\n",
      "  Mean: 0.614577054977417\n",
      "\n",
      "Feature 11:\n",
      "  Min: -290.1986999511719\n",
      "  Max: 272.33258056640625\n",
      "  Mean: 0.11136796325445175\n",
      "\n",
      "Feature 12:\n",
      "  Min: -248.4126434326172\n",
      "  Max: 296.6640625\n",
      "  Mean: 6.226540565490723\n",
      "\n",
      "Feature 13:\n",
      "  Min: -279.6750793457031\n",
      "  Max: 275.9710693359375\n",
      "  Mean: 0.12976601719856262\n",
      "\n",
      "Feature 14:\n",
      "  Min: -324.2652587890625\n",
      "  Max: 284.65869140625\n",
      "  Mean: 0.6562679409980774\n",
      "\n",
      "Feature 15:\n",
      "  Min: -295.87799072265625\n",
      "  Max: 244.2346954345703\n",
      "  Mean: -1.8333743810653687\n",
      "\n",
      "Feature 16:\n",
      "  Min: -259.19720458984375\n",
      "  Max: 287.4547424316406\n",
      "  Mean: -0.47086209058761597\n",
      "\n",
      "Feature 17:\n",
      "  Min: -270.8080749511719\n",
      "  Max: 256.9818420410156\n",
      "  Mean: 0.2870848774909973\n",
      "\n",
      "Feature 18:\n",
      "  Min: -305.4359130859375\n",
      "  Max: 263.6712951660156\n",
      "  Mean: -1.8762727975845337\n",
      "\n",
      "Feature 19:\n",
      "  Min: -304.14093017578125\n",
      "  Max: 255.0359344482422\n",
      "  Mean: -1.0205758810043335\n",
      "\n",
      "Feature 20:\n",
      "  Min: -256.12432861328125\n",
      "  Max: 308.6875\n",
      "  Mean: -0.2765401303768158\n",
      "\n",
      "Feature 21:\n",
      "  Min: -303.685791015625\n",
      "  Max: 288.8507995605469\n",
      "  Mean: -0.26558634638786316\n",
      "\n",
      "Feature 22:\n",
      "  Min: -309.06805419921875\n",
      "  Max: 330.6642150878906\n",
      "  Mean: -1.5541104078292847\n",
      "\n",
      "Feature 23:\n",
      "  Min: -303.6177978515625\n",
      "  Max: 307.46429443359375\n",
      "  Mean: -0.0563361793756485\n",
      "\n",
      "Feature 24:\n",
      "  Min: -270.34234619140625\n",
      "  Max: 269.294677734375\n",
      "  Mean: -0.42763617634773254\n",
      "\n",
      "Feature 25:\n",
      "  Min: -306.33587646484375\n",
      "  Max: 343.54443359375\n",
      "  Mean: -0.3564305007457733\n",
      "\n",
      "Feature 26:\n",
      "  Min: -240.45741271972656\n",
      "  Max: 288.2620849609375\n",
      "  Mean: 0.9717602133750916\n",
      "\n",
      "Feature 27:\n",
      "  Min: -313.8284912109375\n",
      "  Max: 308.5334167480469\n",
      "  Mean: 5.016205310821533\n",
      "\n",
      "Feature 28:\n",
      "  Min: -286.7810363769531\n",
      "  Max: 246.07470703125\n",
      "  Mean: 1.2156920433044434\n",
      "\n",
      "Feature 29:\n",
      "  Min: -316.01312255859375\n",
      "  Max: 356.2351379394531\n",
      "  Mean: 1.1311691999435425\n",
      "\n",
      "Feature 30:\n",
      "  Min: -290.2736511230469\n",
      "  Max: 240.0516815185547\n",
      "  Mean: 0.854597806930542\n",
      "\n",
      "Feature 31:\n",
      "  Min: -323.3015441894531\n",
      "  Max: 285.34381103515625\n",
      "  Mean: 1.2179131507873535\n",
      "\n",
      "Feature 32:\n",
      "  Min: -287.3321838378906\n",
      "  Max: 289.40374755859375\n",
      "  Mean: 2.112093210220337\n",
      "\n",
      "Feature 33:\n",
      "  Min: -294.78863525390625\n",
      "  Max: 256.9644470214844\n",
      "  Mean: 0.6087293028831482\n",
      "\n",
      "Feature 34:\n",
      "  Min: -292.2518005371094\n",
      "  Max: 281.5015869140625\n",
      "  Mean: 3.122642993927002\n",
      "\n",
      "Feature 35:\n",
      "  Min: -294.6162414550781\n",
      "  Max: 286.2907409667969\n",
      "  Mean: 0.9737322330474854\n",
      "\n",
      "Feature 36:\n",
      "  Min: -278.3026123046875\n",
      "  Max: 329.25616455078125\n",
      "  Mean: 1.2391027212142944\n",
      "\n",
      "Feature 37:\n",
      "  Min: -306.9356689453125\n",
      "  Max: 235.12672424316406\n",
      "  Mean: -0.17304033041000366\n",
      "\n",
      "Feature 38:\n",
      "  Min: -230.14068603515625\n",
      "  Max: 312.4045715332031\n",
      "  Mean: 3.55607008934021\n",
      "\n",
      "Feature 39:\n",
      "  Min: -267.3130798339844\n",
      "  Max: 320.2610168457031\n",
      "  Mean: 3.32800555229187\n",
      "\n",
      "Feature 40:\n",
      "  Min: -328.8893127441406\n",
      "  Max: 240.2566680908203\n",
      "  Mean: 0.9918082356452942\n",
      "\n",
      "Feature 41:\n",
      "  Min: -315.9952087402344\n",
      "  Max: 295.9677429199219\n",
      "  Mean: 2.688962936401367\n",
      "\n",
      "Feature 42:\n",
      "  Min: -254.91139221191406\n",
      "  Max: 262.3323669433594\n",
      "  Mean: 1.5284122228622437\n",
      "\n",
      "Feature 43:\n",
      "  Min: -259.51995849609375\n",
      "  Max: 292.76776123046875\n",
      "  Mean: 1.4132195711135864\n",
      "\n",
      "Feature 44:\n",
      "  Min: -273.5960388183594\n",
      "  Max: 256.49407958984375\n",
      "  Mean: 0.882682740688324\n",
      "\n",
      "Feature 45:\n",
      "  Min: -290.2835388183594\n",
      "  Max: 254.29327392578125\n",
      "  Mean: 0.32216671109199524\n",
      "\n",
      "Feature 46:\n",
      "  Min: -290.8634338378906\n",
      "  Max: 278.6734924316406\n",
      "  Mean: 1.8623353242874146\n",
      "\n",
      "Feature 47:\n",
      "  Min: -268.60638427734375\n",
      "  Max: 332.4284362792969\n",
      "  Mean: -0.21290160715579987\n",
      "\n",
      "Feature 48:\n",
      "  Min: -263.34161376953125\n",
      "  Max: 260.9122314453125\n",
      "  Mean: 0.19771309196949005\n",
      "\n",
      "Feature 49:\n",
      "  Min: -251.1982421875\n",
      "  Max: 305.9307556152344\n",
      "  Mean: 0.20493876934051514\n",
      "\n",
      "Feature 50:\n",
      "  Min: -265.5045166015625\n",
      "  Max: 239.00494384765625\n",
      "  Mean: 0.8688279390335083\n",
      "\n",
      "Feature 51:\n",
      "  Min: -276.5945129394531\n",
      "  Max: 308.4158020019531\n",
      "  Mean: 0.30306780338287354\n",
      "\n",
      "Feature 52:\n",
      "  Min: -282.5939025878906\n",
      "  Max: 280.67364501953125\n",
      "  Mean: 0.8563302159309387\n",
      "\n",
      "Feature 53:\n",
      "  Min: -292.3608703613281\n",
      "  Max: 287.8970947265625\n",
      "  Mean: 0.27474936842918396\n",
      "\n",
      "Feature 54:\n",
      "  Min: -273.4208984375\n",
      "  Max: 253.17709350585938\n",
      "  Mean: 0.18690773844718933\n",
      "\n",
      "Feature 55:\n",
      "  Min: -268.6029357910156\n",
      "  Max: 288.0848693847656\n",
      "  Mean: 0.18092744052410126\n",
      "\n",
      "Feature 56:\n",
      "  Min: -248.4884033203125\n",
      "  Max: 261.552490234375\n",
      "  Mean: 1.9500266313552856\n",
      "\n",
      "Feature 57:\n",
      "  Min: -248.727783203125\n",
      "  Max: 280.8067932128906\n",
      "  Mean: 3.068805694580078\n",
      "\n",
      "Feature 58:\n",
      "  Min: -310.78668212890625\n",
      "  Max: 275.01751708984375\n",
      "  Mean: 0.3338477909564972\n",
      "\n",
      "Feature 59:\n",
      "  Min: -389.7436828613281\n",
      "  Max: 270.55078125\n",
      "  Mean: 1.198258638381958\n",
      "\n",
      "Feature 60:\n",
      "  Min: -478.7933044433594\n",
      "  Max: 507.1368408203125\n",
      "  Mean: 16.066362380981445\n",
      "\n",
      "Feature 61:\n",
      "  Min: -570.9963989257812\n",
      "  Max: 909.009521484375\n",
      "  Mean: 24.830230712890625\n",
      "\n",
      "Feature 62:\n",
      "  Min: -760.2193603515625\n",
      "  Max: 714.8755493164062\n",
      "  Mean: 34.911460876464844\n",
      "\n",
      "Feature 63:\n",
      "  Min: -270.5002746582031\n",
      "  Max: 291.0821228027344\n",
      "  Mean: 8.708099365234375\n",
      "\n",
      "Feature 64:\n",
      "  Min: -267.4334716796875\n",
      "  Max: 278.03131103515625\n",
      "  Mean: 0.1774587333202362\n",
      "\n",
      "Feature 65:\n",
      "  Min: -266.6805114746094\n",
      "  Max: 244.1674346923828\n",
      "  Mean: 2.3781914710998535\n",
      "\n",
      "Feature 66:\n",
      "  Min: -296.13629150390625\n",
      "  Max: 249.29054260253906\n",
      "  Mean: -1.282372236251831\n",
      "\n",
      "Feature 67:\n",
      "  Min: -302.9154052734375\n",
      "  Max: 275.6488342285156\n",
      "  Mean: -0.6024376749992371\n",
      "\n",
      "Feature 68:\n",
      "  Min: -506.43402099609375\n",
      "  Max: 263.88958740234375\n",
      "  Mean: -16.254234313964844\n",
      "\n",
      "Feature 69:\n",
      "  Min: -266.3335266113281\n",
      "  Max: 284.4508056640625\n",
      "  Mean: 0.6026306748390198\n",
      "\n",
      "Feature 70:\n",
      "  Min: -290.57086181640625\n",
      "  Max: 302.57720947265625\n",
      "  Mean: -1.310675024986267\n",
      "\n",
      "Feature 71:\n",
      "  Min: -312.8423156738281\n",
      "  Max: 265.25225830078125\n",
      "  Mean: 0.5351918339729309\n",
      "\n",
      "Feature 72:\n",
      "  Min: -289.0487060546875\n",
      "  Max: 309.0981140136719\n",
      "  Mean: 4.175189018249512\n",
      "\n",
      "Feature 73:\n",
      "  Min: -247.1409149169922\n",
      "  Max: 299.9022521972656\n",
      "  Mean: -0.3578721284866333\n",
      "\n",
      "Feature 74:\n",
      "  Min: -352.35107421875\n",
      "  Max: 255.25621032714844\n",
      "  Mean: -0.5742373466491699\n",
      "\n",
      "Feature 75:\n",
      "  Min: -325.7056579589844\n",
      "  Max: 249.99221801757812\n",
      "  Mean: -1.081928014755249\n",
      "\n",
      "Feature 76:\n",
      "  Min: -337.26995849609375\n",
      "  Max: 294.7023010253906\n",
      "  Mean: -0.15431973338127136\n",
      "\n",
      "Feature 77:\n",
      "  Min: -315.3390808105469\n",
      "  Max: 308.7372741699219\n",
      "  Mean: 1.568788766860962\n",
      "\n",
      "Feature 78:\n",
      "  Min: -273.2850646972656\n",
      "  Max: 244.33021545410156\n",
      "  Mean: -1.5388716459274292\n",
      "\n",
      "Feature 79:\n",
      "  Min: -295.3943786621094\n",
      "  Max: 265.4295349121094\n",
      "  Mean: 0.9540995359420776\n",
      "\n",
      "Feature 80:\n",
      "  Min: -283.2618713378906\n",
      "  Max: 277.76971435546875\n",
      "  Mean: -0.6345359086990356\n",
      "\n",
      "Feature 81:\n",
      "  Min: -292.0600891113281\n",
      "  Max: 271.0494689941406\n",
      "  Mean: -0.18735967576503754\n",
      "\n",
      "Feature 82:\n",
      "  Min: -290.0262451171875\n",
      "  Max: 301.62451171875\n",
      "  Mean: -0.06012864038348198\n",
      "\n",
      "Feature 83:\n",
      "  Min: -268.70172119140625\n",
      "  Max: 252.11390686035156\n",
      "  Mean: 0.7055245041847229\n",
      "\n",
      "Feature 84:\n",
      "  Min: -286.9475402832031\n",
      "  Max: 243.56765747070312\n",
      "  Mean: -1.7957700490951538\n",
      "\n",
      "Feature 85:\n",
      "  Min: -255.58692932128906\n",
      "  Max: 277.9204406738281\n",
      "  Mean: 0.6904878616333008\n",
      "\n",
      "Feature 86:\n",
      "  Min: -277.4393310546875\n",
      "  Max: 307.15081787109375\n",
      "  Mean: 0.7640300989151001\n",
      "\n",
      "Feature 87:\n",
      "  Min: -260.7162170410156\n",
      "  Max: 290.7450866699219\n",
      "  Mean: 2.8302526473999023\n",
      "\n",
      "Feature 88:\n",
      "  Min: -294.7259216308594\n",
      "  Max: 277.9848937988281\n",
      "  Mean: 1.4979780912399292\n",
      "\n",
      "Feature 89:\n",
      "  Min: -305.6308288574219\n",
      "  Max: 307.5625\n",
      "  Mean: 3.413696050643921\n",
      "\n",
      "Feature 90:\n",
      "  Min: -354.3463134765625\n",
      "  Max: 354.79339599609375\n",
      "  Mean: 2.247738838195801\n",
      "\n",
      "Feature 91:\n",
      "  Min: -386.8149108886719\n",
      "  Max: 261.6107482910156\n",
      "  Mean: 3.9167280197143555\n",
      "\n",
      "Feature 92:\n",
      "  Min: -270.672119140625\n",
      "  Max: 362.9037780761719\n",
      "  Mean: 3.61834979057312\n",
      "\n",
      "Feature 93:\n",
      "  Min: -274.89801025390625\n",
      "  Max: 281.12908935546875\n",
      "  Mean: 1.2269659042358398\n",
      "\n",
      "Feature 94:\n",
      "  Min: -296.02996826171875\n",
      "  Max: 268.3395080566406\n",
      "  Mean: 0.27727097272872925\n",
      "\n",
      "Feature 95:\n",
      "  Min: -279.4962158203125\n",
      "  Max: 264.1806335449219\n",
      "  Mean: 2.9642462730407715\n",
      "\n",
      "Feature 96:\n",
      "  Min: -317.8184509277344\n",
      "  Max: 276.83740234375\n",
      "  Mean: 0.9751405715942383\n",
      "\n",
      "Feature 97:\n",
      "  Min: -310.67822265625\n",
      "  Max: 270.96270751953125\n",
      "  Mean: -0.22416840493679047\n",
      "\n",
      "Feature 98:\n",
      "  Min: -276.1763916015625\n",
      "  Max: 295.7355041503906\n",
      "  Mean: 2.725818395614624\n",
      "\n",
      "Feature 99:\n",
      "  Min: -286.0380554199219\n",
      "  Max: 273.22698974609375\n",
      "  Mean: 1.4033207893371582\n",
      "\n",
      "Feature 100:\n",
      "  Min: -276.1846618652344\n",
      "  Max: 390.9407043457031\n",
      "  Mean: 3.2513539791107178\n",
      "\n",
      "Feature 101:\n",
      "  Min: -319.8136291503906\n",
      "  Max: 266.33978271484375\n",
      "  Mean: 2.532221555709839\n",
      "\n",
      "Feature 102:\n",
      "  Min: -354.30841064453125\n",
      "  Max: 315.15936279296875\n",
      "  Mean: 3.0708823204040527\n",
      "\n",
      "Feature 103:\n",
      "  Min: -320.201904296875\n",
      "  Max: 290.1944885253906\n",
      "  Mean: 1.1194876432418823\n",
      "\n",
      "Feature 104:\n",
      "  Min: -273.980712890625\n",
      "  Max: 260.64410400390625\n",
      "  Mean: -1.8252366781234741\n",
      "\n",
      "Feature 105:\n",
      "  Min: -263.24053955078125\n",
      "  Max: 296.0483093261719\n",
      "  Mean: 1.515717625617981\n",
      "\n",
      "Feature 106:\n",
      "  Min: -278.3028259277344\n",
      "  Max: 291.05682373046875\n",
      "  Mean: 0.580905556678772\n",
      "\n",
      "Feature 107:\n",
      "  Min: -276.6535339355469\n",
      "  Max: 271.949462890625\n",
      "  Mean: 0.6540665030479431\n",
      "\n",
      "Feature 108:\n",
      "  Min: -265.6163024902344\n",
      "  Max: 264.50335693359375\n",
      "  Mean: 1.0900324583053589\n",
      "\n",
      "Feature 109:\n",
      "  Min: -289.90447998046875\n",
      "  Max: 288.3970031738281\n",
      "  Mean: 0.3302668631076813\n",
      "\n",
      "Feature 110:\n",
      "  Min: -280.0899658203125\n",
      "  Max: 330.88055419921875\n",
      "  Mean: 0.18392057716846466\n",
      "\n",
      "Feature 111:\n",
      "  Min: -291.7430725097656\n",
      "  Max: 248.9168243408203\n",
      "  Mean: -0.22658468782901764\n",
      "\n",
      "Feature 112:\n",
      "  Min: -305.7737121582031\n",
      "  Max: 267.42413330078125\n",
      "  Mean: 0.689139723777771\n",
      "\n",
      "Feature 113:\n",
      "  Min: -289.3703308105469\n",
      "  Max: 250.1055145263672\n",
      "  Mean: -0.4195069968700409\n",
      "\n",
      "Feature 114:\n",
      "  Min: -311.17987060546875\n",
      "  Max: 277.15167236328125\n",
      "  Mean: -0.6385021209716797\n",
      "\n",
      "Feature 115:\n",
      "  Min: -257.77490234375\n",
      "  Max: 267.88677978515625\n",
      "  Mean: 0.8098108172416687\n",
      "\n",
      "Feature 116:\n",
      "  Min: -284.2120666503906\n",
      "  Max: 274.7660217285156\n",
      "  Mean: 2.3204877376556396\n",
      "\n",
      "Feature 117:\n",
      "  Min: -264.2425537109375\n",
      "  Max: 292.49310302734375\n",
      "  Mean: 1.2797057628631592\n",
      "\n",
      "Feature 118:\n",
      "  Min: -272.09735107421875\n",
      "  Max: 274.41571044921875\n",
      "  Mean: -0.9058626294136047\n",
      "\n",
      "Feature 119:\n",
      "  Min: -250.7581787109375\n",
      "  Max: 265.1603698730469\n",
      "  Mean: 0.6579137444496155\n",
      "\n",
      "Feature 120:\n",
      "  Min: -240.98573303222656\n",
      "  Max: 303.24542236328125\n",
      "  Mean: 10.131852149963379\n",
      "\n",
      "Feature 121:\n",
      "  Min: -401.04632568359375\n",
      "  Max: 227.40292358398438\n",
      "  Mean: -7.06116247177124\n",
      "\n",
      "Feature 122:\n",
      "  Min: -237.1899871826172\n",
      "  Max: 304.190185546875\n",
      "  Mean: 0.6129637956619263\n",
      "\n",
      "Feature 123:\n",
      "  Min: -276.4895324707031\n",
      "  Max: 255.3562774658203\n",
      "  Mean: 1.4425736665725708\n",
      "\n",
      "Feature 124:\n",
      "  Min: -276.55859375\n",
      "  Max: 249.60723876953125\n",
      "  Mean: -0.5808164477348328\n",
      "\n",
      "Feature 125:\n",
      "  Min: -332.8038330078125\n",
      "  Max: 265.3880310058594\n",
      "  Mean: -1.3771544694900513\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def inspect_generated_trajectories(file_path):\n",
    "    memmap = np.memmap(file_path, dtype='float32', mode='r')\n",
    "    \n",
    "    print(f\"Raw shape of generated trajectories: {memmap.shape}\")\n",
    "    print(f\"Total number of elements: {memmap.size}\")\n",
    "    \n",
    "    # Try to infer the correct shape\n",
    "    total_elements = memmap.size\n",
    "    num_trajectories = 1000  # As specified in your generation code\n",
    "    seq_len = 1000  # From your original data\n",
    "    \n",
    "    if total_elements % (num_trajectories * seq_len) == 0:\n",
    "        num_features = total_elements // (num_trajectories * seq_len)\n",
    "        print(f\"Inferred shape: ({num_trajectories}, {seq_len}, {num_features})\")\n",
    "        \n",
    "        # Reshape the memmap\n",
    "        trajectories = memmap.reshape((num_trajectories, seq_len, num_features))\n",
    "        \n",
    "        print(f\"Data type: {trajectories.dtype}\")\n",
    "        print(f\"Min value: {np.min(trajectories)}\")\n",
    "        print(f\"Max value: {np.max(trajectories)}\")\n",
    "        print(f\"Mean value: {np.mean(trajectories)}\")\n",
    "        print(f\"Has NaNs: {np.isnan(trajectories).any()}\")\n",
    "        print(f\"Has Infs: {np.isinf(trajectories).any()}\")\n",
    "        \n",
    "        # Print statistics for each feature\n",
    "        for i in range(num_features):\n",
    "            print(f\"\\nFeature {i}:\")\n",
    "            print(f\"  Min: {np.min(trajectories[:,:,i])}\")\n",
    "            print(f\"  Max: {np.max(trajectories[:,:,i])}\")\n",
    "            print(f\"  Mean: {np.mean(trajectories[:,:,i])}\")\n",
    "    else:\n",
    "        print(\"Unable to infer the correct shape. Please check the generation process.\")\n",
    "\n",
    "# Use the function\n",
    "inspect_generated_trajectories('generated_trajectories.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b17c3aeb-e8ef-4133-9403-79793de0d7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset converted and saved as 'generated_dataset.h5'\n",
      "Dataset ready for training\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def convert_and_save_generated_trajectories(generated_trajectories, output_file='generated_dataset.h5', seq_len=1000):\n",
    "    \"\"\"\n",
    "    Convert generated trajectories to the format expected by the training algorithm,\n",
    "    save as an HDF5 file, and return the dataset dictionary.\n",
    "    \n",
    "    :param generated_trajectories: numpy array of shape (num_trajectories, seq_len, num_features)\n",
    "    :param output_file: name of the output HDF5 file\n",
    "    :param seq_len: length of each trajectory\n",
    "    :return: dictionary containing the dataset in the required format\n",
    "    \"\"\"\n",
    "    num_trajectories, _, num_features = generated_trajectories.shape\n",
    "    \n",
    "    # Assuming the last 6 features are: rewards, costs, terminals, timeouts, actions (2D)\n",
    "    observations = generated_trajectories[:, :, :60]\n",
    "    next_observations = np.roll(observations, -1, axis=1)\n",
    "    next_observations[:, -1] = observations[:, -1]  # Last step\n",
    "    actions = generated_trajectories[:, :, -2:]\n",
    "    rewards = generated_trajectories[:, :, -6]\n",
    "    costs = generated_trajectories[:, :, -5]\n",
    "    terminals = generated_trajectories[:, :, -4].astype(bool)\n",
    "    timeouts = generated_trajectories[:, :, -3].astype(bool)\n",
    "    \n",
    "    # Create the dataset dictionary\n",
    "    dataset = {\n",
    "        'observations': observations.reshape(-1, 60),\n",
    "        'next_observations': next_observations.reshape(-1, 60),\n",
    "        'actions': actions.reshape(-1, 2),\n",
    "        'rewards': rewards.flatten(),\n",
    "        'costs': costs.flatten(),\n",
    "        'terminals': terminals.flatten(),\n",
    "        'timeouts': timeouts.flatten()\n",
    "    }\n",
    "    \n",
    "    # Save the dataset in HDF5 format\n",
    "    with h5py.File(output_file, 'w') as f:\n",
    "        for key, value in dataset.items():\n",
    "            f.create_dataset(key, data=value)\n",
    "    \n",
    "    print(f\"Dataset converted and saved as '{output_file}'\")\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Load the generated trajectories\n",
    "generated_trajectories = np.memmap('generated_trajectories.npy', dtype='float32', mode='r').reshape(1000, 1000, 126)\n",
    "\n",
    "# Convert to dataset format, save as HDF5, and get the dataset dictionary\n",
    "dataset = convert_and_save_generated_trajectories(generated_trajectories)\n",
    "\n",
    "print(\"Dataset ready for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3facec14-850d-458e-bce2-6e510adf3da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
